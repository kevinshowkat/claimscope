name: Claimscope SWE-bench Verification

on:
  pull_request:
    paths:
      - 'bundles/**'
      - 'schemas/**'
      - 'tools/claimscope_bundle_validate.py'
      - '.github/workflows/claimscope-verify.yml'

jobs:
  swebench-verify:
    name: Validate bundles and run SWE-bench harness
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install swebench==3.0.17 jsonschema PyYAML ruff mypy

      - name: Install gitleaks
        run: |
          curl -sSfL https://raw.githubusercontent.com/gitleaks/gitleaks/master/install.sh | bash -s -- -b /usr/local/bin

      - name: Validate prediction bundles
        id: validate
        run: |
          set -euo pipefail
          BASE_REF="${{ github.base_ref }}"
          if [[ -z "$BASE_REF" ]]; then
            BASE_REF="${{ github.event.repository.default_branch }}"
          fi
          git fetch origin "$BASE_REF":"refs/remotes/origin/${BASE_REF}"
          mapfile -t CHANGED < <(git diff --name-only "origin/${BASE_REF}...HEAD" -- 'bundles/**/MANIFEST.yaml' 'bundles/**/*.jsonl')
          if [[ ${#CHANGED[@]} -eq 0 ]]; then
            echo "no_bundles=1" >> "$GITHUB_OUTPUT"
            echo "No bundle changes detected"
            exit 0
          fi
          declare -A SEEN
          for path in "${CHANGED[@]}"; do
            dir=$(dirname "$path")
            SEEN["$dir"]=1
          done
          for bundle in "${!SEEN[@]}"; do
            echo "Validating $bundle"
            python tools/claimscope_bundle_validate.py "$bundle"
          done
          printf '%s\n' "${CHANGED[@]}" > changed_files.txt
          echo "changed_manifest_list=$(pwd)/changed_files.txt" >> "$GITHUB_OUTPUT"
          echo "no_bundles=0" >> "$GITHUB_OUTPUT"

      - name: Run SWE-bench harness on changed instances
        if: steps.validate.outputs.no_bundles == '0'
        env:
          GITHUB_RUN_ID: ${{ github.run_id }}
        run: |
          set -euo pipefail
          BASE_REF="${{ github.base_ref }}"
          if [[ -z "$BASE_REF" ]]; then
            BASE_REF="${{ github.event.repository.default_branch }}"
          fi
          mapfile -t PREDICTIONS < <(git diff --name-only "origin/${BASE_REF}...HEAD" -- 'bundles/**/*.jsonl')
          if [[ ${#PREDICTIONS[@]} -eq 0 ]]; then
            echo "No prediction files modified"
            exit 0
          fi
          printf '%s\n' "${PREDICTIONS[@]}" > predictions.txt
          export BASE_REF_REF="origin/${BASE_REF}"
          python <<'PY'
import json
import os
import subprocess
from pathlib import Path

import yaml

base_ref = os.environ.get('BASE_REF_REF')
if not base_ref:
    raise SystemExit('BASE_REF_REF not provided')

predictions_file = Path('predictions.txt')
prediction_paths = [line.strip() for line in predictions_file.read_text(encoding='utf-8').splitlines() if line.strip()]
if not prediction_paths:
    raise SystemExit('No prediction file paths provided')


def load_entries_from_ref(path: str) -> dict[str, dict]:
    result = subprocess.run(
        ['git', 'show', f'{base_ref}:{path}'],
        check=False,
        text=True,
        capture_output=True,
    )
    if result.returncode != 0:
        return {}
    entries: dict[str, dict] = {}
    for line in result.stdout.splitlines():
        line = line.strip()
        if not line:
            continue
        obj = json.loads(line)
        entries[obj['instance_id']] = obj
    return entries


for rel_path in prediction_paths:
    predictions_path = Path(rel_path)
    manifest_path = predictions_path.with_name('MANIFEST.yaml')
    if not manifest_path.exists():
        raise SystemExit(f'Manifest not found for {predictions_path}')

    manifest = yaml.safe_load(manifest_path.read_text(encoding='utf-8')) or {}
    dataset = manifest.get('dataset', 'princeton-nlp/SWE-bench_Verified')
    split = manifest.get('split', 'test')

    current_entries: list[dict] = []
    with predictions_path.open('r', encoding='utf-8') as handle:
        for line in handle:
            line = line.strip()
            if not line:
                continue
            current_entries.append(json.loads(line))

    previous_entries = load_entries_from_ref(rel_path)
    changed_ids = [
        entry['instance_id']
        for entry in current_entries
        if previous_entries.get(entry['instance_id']) != entry
    ]

    if not changed_ids:
        continue

    cmd = [
        'python',
        'packages/harness/swebench/cli.py',
        '--predictions',
        str(predictions_path),
        '--dataset-name',
        dataset,
        '--split',
        split,
        '--run-id',
        f"github_{os.environ.get('GITHUB_RUN_ID')}_{predictions_path.stem}",
    ]
    for instance_id in changed_ids:
        cmd.extend(['--instance-id', instance_id])

    print('Running harness:', ' '.join(cmd))
    subprocess.run(cmd, check=True)
PY
